#!/usr/bin/env python3
import rclpy
from rclpy.node import Node
from sensor_msgs.msg import Image
from cv_bridge import CvBridge
import cv2
import numpy as np
from message_filters import ApproximateTimeSynchronizer, Subscriber
from sensor_msgs.msg import CameraInfo
from hot.msg import StepEvent  # ì‚¬ìš©ì ì •ì˜ ë©”ì‹œì§€


class HorizontalLineDepthDetector(Node):
    def __init__(self):
        super().__init__('horizontal_line_depth_detector')
        self.bridge = CvBridge()

        # ì¹´ë©”ë¼ ì„¤ì¹˜ ë†’ì´ (ë¯¸í„°): ì¹´ë©”ë¼ ì„¼ì„œì—ì„œ ë°”ë‹¥ê¹Œì§€ì˜ ìˆ˜ì§ ê±°ë¦¬
        self.camera_height_m = 0.235
        
        self.camera_info_received = False

        self.camera_info_sub = self.create_subscription(CameraInfo,'/camera/color/camera_info',self.camera_info_callback,10)
        # ë©”ì‹œì§€ í•„í„° ê¸°ë°˜ ë™ê¸°í™” êµ¬ë…ì (ì»¬ëŸ¬ + ëìŠ¤)
        self.color_sub = Subscriber(self, Image, '/camera/color/image_raw')
        self.depth_sub = Subscriber(self, Image, '/camera/aligned_depth_to_color/image_raw')

        self.step_pub = self.create_publisher(StepEvent, '/step_detected', 10)

        self.ts = ApproximateTimeSynchronizer([self.color_sub, self.depth_sub], queue_size=10, slop=0.1)
        self.ts.registerCallback(self.image_callback)

        self.get_logger().info("HorizontalLineDepthDetector node initialized.")
        self.get_logger().info(f"ì¹´ë©”ë¼ ë†’ì´: {self.camera_height_m*100:.1f}cm")
        
    def camera_info_callback(self, msg):
        self.fx = msg.k[0]
        self.fy = msg.k[4]
        self.cx = msg.k[2]
        self.cy = msg.k[5]
        self.camera_info_received = True

    def image_callback(self, color_msg, depth_msg):
        try:
            color_image = self.bridge.imgmsg_to_cv2(color_msg, desired_encoding='bgr8')
            depth_image = self.bridge.imgmsg_to_cv2(depth_msg, desired_encoding='passthrough')
        except Exception as e:
            self.get_logger().error(f"CV Bridge ë³€í™˜ ì‹¤íŒ¨: {e}")
            return

        if not self.camera_info_received:
            self.get_logger().warn("ì¹´ë©”ë¼ ë‚´ë¶€ íŒŒë¼ë¯¸í„°ë¥¼ ì•„ì§ ë°›ì§€ ëª»í–ˆìŠµë‹ˆë‹¤.")
            return
        # ì›ë³¸ ì´ë¯¸ì§€ ë³µì‚¬
        debug_image = color_image.copy()
        
        # ì—£ì§€ ê²€ì¶œ ë° ìˆ˜í‰ì„  ì°¾ê¸°
        gray = cv2.cvtColor(color_image, cv2.COLOR_BGR2GRAY)
        gray = cv2.GaussianBlur(gray, (5, 5), 2)
        edge = cv2.Canny(gray, 50, 150, 3)

        lines = cv2.HoughLinesP(edge, 1, np.pi / 180, 200, minLineLength=50, maxLineGap=10)
        if lines is None:
            cv2.imshow("Detected Lines", debug_image)
            cv2.waitKey(1)
            return

        # ìˆ˜í‰ì„  í•„í„°ë§
        min_angle = -1.0 * (np.pi / 180.0)
        max_angle = 1.0 * (np.pi / 180.0)
        horizontal_lines = []
        merged_lines = []
        height_threshold = 50

        for l in lines:
            x1, y1, x2, y2 = l[0]
            angle = np.arctan2(y2 - y1, x2 - x1)
            if min_angle < angle < max_angle:
                horizontal_lines.append((x1, y1, x2, y2))

        # ìœ ì‚¬í•œ ë†’ì´ì˜ ìˆ˜í‰ì„  ë³‘í•©
        for l1 in horizontal_lines:
            merged = False
            for i, l2 in enumerate(merged_lines):
                if abs(l1[1] - l2[1]) < height_threshold and abs(l1[3] - l2[3]) < height_threshold:
                    l2[0] = min(l2[0], l1[0])
                    l2[1] = (l2[1] + l1[1]) // 2
                    l2[2] = max(l2[2], l1[2])
                    l2[3] = (l2[3] + l1[3]) // 2
                    merged = True
                    break
            if not merged:
                merged_lines.append(list(l1))

        # ê° ìˆ˜í‰ì„ ì˜ 3D ì •ë³´ ê³„ì‚° ë° í‘œì‹œ
        for i, (x1, y1, x2, y2) in enumerate(merged_lines):
            mid_x = (x1 + x2) // 2
            mid_y = (y1 + y2) // 2
            if mid_y >= depth_image.shape[0] or mid_x >= depth_image.shape[1]:
                continue

            # ì¤‘ì•™ì ì˜ ê¹Šì´ ê°’ (mm)
            depth_val = depth_image[mid_y, mid_x]

            if depth_val == 0 or np.isnan(depth_val):
                continue

            # mm â†’ m ë³€í™˜ (RealSense ëìŠ¤ëŠ” ê¸°ë³¸ì ìœ¼ë¡œ mm ë‹¨ìœ„)
            if depth_image.dtype == np.uint16:
                depth_val = depth_val / 1000.0  # mm â†’ m

            # 3D ì¢Œí‘œ ê³„ì‚° (ì¹´ë©”ë¼ ì¢Œí‘œê³„)
            X = (mid_x - self.cx) * depth_val / self.fx
            Y = (mid_y - self.cy) * depth_val / self.fy
            Z = depth_val

            # ì¹´ë©”ë¼ë¡œë¶€í„°ì˜ ì‹¤ì œ ë†’ì´ ê³„ì‚° (ë°”ë‹¥ ê¸°ì¤€, ë¯¸í„°)
            # RealSense ì¹´ë©”ë¼ì—ì„œ YëŠ” ì•„ë˜ìª½ì´ ì–‘ìˆ˜ì´ë¯€ë¡œ
            # ì§€ë©´ìœ¼ë¡œë¶€í„°ì˜ ë†’ì´ëŠ” ì¹´ë©”ë¼ ë†’ì´ì—ì„œ Yê°’ì„ ë¹¼ì¤€ ê°’
            height_from_ground = self.camera_height_m - Y
            
            # í„°ë¯¸ë„ì— ì •ë³´ ì¶œë ¥
            self.get_logger().info(
                f"[ìˆ˜í‰ì„  #{i}] ìœ„ì¹˜: ({mid_x},{mid_y}) | ê¹Šì´: {Z:.2f}m | Yì¢Œí‘œ: {Y:.3f}m | ì§€ë©´ ë†’ì´: {height_from_ground*100:.1f}cm"
            )

            #if height_from_ground > 0.05:
            #    msg = StepEvent()
            #    msg.height = float(height_from_ground)  # ğŸ”¥ í•µì‹¬ ìˆ˜ì •
            #   self.step_pub.publish(msg)
            #    self.get_logger().info(f"[StepEvent] ë‹¨ì°¨ ê°ì§€ â†’ ë†’ì´: {height_from_ground:.3f} m â†’ ë©”ì‹œì§€ ë°œí–‰ ì™„ë£Œ")

            # ë‹¨ì°¨ ë†’ì´ ì¡°ê±´ (5cm ì´ìƒ 20cm ì´í•˜ë§Œ í—ˆìš©)
            if  height_from_ground < 0.20:
                msg = StepEvent()
                msg.height = float(height_from_ground)
                self.step_pub.publish(msg)
                self.get_logger().info(f"[StepEvent] ë‹¨ì°¨ ê°ì§€ â†’ ë†’ì´: {height_from_ground:.3f} m â†’ ë©”ì‹œì§€ ë°œí–‰ ì™„ë£Œ")

            # ìˆ˜í‰ì„  ê·¸ë¦¬ê¸° (íŒŒë€ìƒ‰)
            cv2.line(debug_image, (x1, y1), (x2, y2), (255, 0, 0), 2)
            
            # ì¤‘ì•™ì  í‘œì‹œ (ì´ˆë¡ìƒ‰)
            cv2.circle(debug_image, (mid_x, mid_y), 5, (0, 255, 0), -1)
            
            # ë†’ì´ ì •ë³´ í‘œì‹œ (í°ìƒ‰)
            cv2.putText(debug_image, 
                      f"{height_from_ground*100:.1f}cm", 
                      (mid_x+10, mid_y),
                      cv2.FONT_HERSHEY_SIMPLEX, 0.8, (255, 255, 255), 2)
            
            # ê¹Šì´ ì •ë³´ í‘œì‹œ (ë…¸ë€ìƒ‰)
            cv2.putText(debug_image, 
                      f"Z:{Z:.2f}m", 
                      (mid_x+10, mid_y+25),
                      cv2.FONT_HERSHEY_SIMPLEX, 0.6, (0, 255, 255), 2)

        cv2.imshow("Detected Lines", debug_image)
        cv2.waitKey(1)


def main(args=None):
    rclpy.init(args=args)
    node = HorizontalLineDepthDetector()
    try:
        rclpy.spin(node)
    except KeyboardInterrupt:
        pass
    node.destroy_node()
    rclpy.shutdown()
    cv2.destroyAllWindows()

if __name__ == '__main__':
    main()